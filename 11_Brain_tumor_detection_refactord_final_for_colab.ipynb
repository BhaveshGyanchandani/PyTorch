{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmV8pMt2Lgzg",
        "outputId": "f345bd38-525d-49a3-f8f1-daed96b5d142"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: monai in /usr/local/lib/python3.11/dist-packages (1.4.0)\n",
            "Collecting numpy<2.0,>=1.24 (from monai)\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.11/dist-packages (from monai) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9->monai) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9->monai) (3.0.2)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.5\n",
            "    Uninstalling numpy-2.2.5:\n",
            "      Successfully uninstalled numpy-2.2.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        }
      ],
      "source": [
        "!pip install monai #--upgrade --force-reinstall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCuTFeE5vMHA",
        "outputId": "15dcdcbd-ef8e-44e3-ad9b-837b2afff8e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy\n",
            "  Using cached numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Using cached numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "monai 1.4.0 requires numpy<2.0,>=1.24, but you have numpy 2.2.5 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.5 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.2.5\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --force-reinstall numpy\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMgLn_-vKL20"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from glob import glob\n",
        "from natsort import natsorted\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import nibabel as nib\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from monai.data import DataLoader, Dataset, CacheDataset, pad_list_data_collate\n",
        "from monai.utils import set_determinism\n",
        "from monai.transforms import (\n",
        "    Compose,\n",
        "    EnsureChannelFirstd,\n",
        "    EnsureTyped,\n",
        "    LoadImaged,\n",
        "    MapTransform,\n",
        "    NormalizeIntensityd,\n",
        "    Orientationd,\n",
        "    RandFlipd,\n",
        "    RandScaleIntensityd,\n",
        "    RandShiftIntensityd,\n",
        "    Spacingd,\n",
        "    ToTensord,\n",
        "    SpatialCropd,\n",
        "    RandAdjustContrastd,\n",
        "    RandGaussianNoised,\n",
        "    RandCoarseShuffled,\n",
        "    CropForegroundd,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rb16KXHTKL24",
        "outputId": "ab1a2954-682f-4021-d220-209c69442d1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu' )\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enOsKL0NV-Y-",
        "outputId": "67fd7597-6973-4c7f-e4e5-c6c86e3ca2ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PI-XzroFKL25"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxPIp6dFL1-X",
        "outputId": "6e9041a8-1905-4a18-f779-54f8f6a0c6f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdZsuaMML5ZJ",
        "outputId": "1092feb6-8017-4ad1-a509-f43990999213"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ File does not exist.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "file_path = \"/content/drive/My Drive/Brain_tumor/unet_model_v5.pth\"\n",
        "\n",
        "if os.path.exists(file_path):\n",
        "    print(\"✅ File exists.\")\n",
        "else:\n",
        "    print(\"❌ File does not exist.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1ee8xmzL-70",
        "outputId": "f16d0968-f94f-498a-e2d7-7c8a5456ac34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder exists.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "folder_path = \"/content/drive/My Drive/MICCAI_BraTS2020_TrainingData\"\n",
        "\n",
        "if os.path.exists(folder_path):\n",
        "    print(\"Folder exists.\")\n",
        "else:\n",
        "    print(\"Folder does not exist.\")\n",
        "\n",
        "\n",
        "# array = glob(os.path.join(folder_path, '*'))\n",
        "# len(array) = > 125"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkUKcXUEKL25",
        "outputId": "c3f94d5c-3728-4f2d-b45a-91e0eca2a840"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu' )\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDhUXiLzKL26"
      },
      "outputs": [],
      "source": [
        "class RelabelTransform(MapTransform):\n",
        "    def __init__(self, keys, old_label, new_label):\n",
        "        super().__init__(keys)\n",
        "        self.old_label = old_label\n",
        "        self.new_label = new_label\n",
        "\n",
        "    def __call__(self, data):\n",
        "\n",
        "        d = dict(data)\n",
        "\n",
        "        for key in self.keys:\n",
        "            d[key][d[key] == self.old_label] = self.new_label\n",
        "        return d\n",
        "\n",
        "\n",
        "\n",
        "def prepare(\n",
        "            in_dir,\n",
        "            pixdim=(1.2, 1.2,1.0),\n",
        "            spatial_size=[160, 160, 128],\n",
        "            gamma=(0.5,0.8),\n",
        "            roi_center=[100,100,79],\n",
        "            roi_size =[160, 160, 128],\n",
        "            cache=True,\n",
        "            start_file=0,\n",
        "            end_file=None,\n",
        "            train_size=0.8):\n",
        "\n",
        "    set_determinism(seed=0)\n",
        "\n",
        "    flair = natsorted(glob(os.path.join(in_dir, '*/*flair.nii')))[start_file : end_file]\n",
        "    t1 = natsorted(glob(os.path.join(in_dir, '*/*t1.nii')))[start_file : end_file]\n",
        "    t1ce = natsorted(glob(os.path.join(in_dir, '*/*t1ce.nii')))[start_file : end_file]\n",
        "    t2 = natsorted(glob(os.path.join(in_dir, '*/*t2.nii')))[start_file : end_file]\n",
        "    mask = natsorted(glob(os.path.join(in_dir, '*/*seg.nii')))[start_file : end_file]\n",
        "\n",
        "    full_dataset = [{\"vol\": [flair,t1ce,t2,t1], \"seg\": mask} for flair,t1ce,t2,t1,mask in\n",
        "                   zip(flair,t1ce,t2,t1,mask)]\n",
        "\n",
        "    train_size = int(train_size * len(full_dataset))\n",
        "    val_size = len(full_dataset) - train_size\n",
        "\n",
        "\n",
        "    train_dataset, val_dataset = random_split(\n",
        "    full_dataset,\n",
        "    [train_size, val_size],\n",
        "    generator=torch.Generator().manual_seed(42)  # Set seed for reproducibility\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    train_transform = Compose(\n",
        "        [\n",
        "            LoadImaged(keys=[\"vol\", \"seg\"]),\n",
        "            EnsureChannelFirstd(keys=[\"vol\", \"seg\"]),\n",
        "            EnsureTyped(keys=[\"vol\", \"seg\"]),\n",
        "\n",
        "            Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
        "            Spacingd(keys=[\"vol\", \"seg\"], pixdim=pixdim, mode=(\"bilinear\", \"nearest\")),\n",
        "            RelabelTransform(keys=[\"seg\"], old_label=4, new_label=3),\n",
        "\n",
        "            SpatialCropd(keys=[\"vol\",\"seg\"], roi_center=roi_center ,roi_size=roi_size ),\n",
        "\n",
        "            # RandFlipd(keys=[\"vol\", \"seg\"], prob=0.5, spatial_axis=0),\n",
        "            # RandFlipd(keys=[\"vol\", \"seg\"], prob=0.5, spatial_axis=1),\n",
        "            # RandFlipd(keys=[\"vol\", \"seg\"], prob=0.5, spatial_axis=2),\n",
        "\n",
        "            RandGaussianNoised(keys=[\"vol\"], prob=0.6, mean=0.0, std=0.05),\n",
        "\n",
        "            # RandCoarseShuffled(\n",
        "            # keys=[\"vol\"],\n",
        "            # prob=0.5,\n",
        "            # holes=6 ,\n",
        "            # spatial_size=(12, 12, 12)\n",
        "            # ),\n",
        "\n",
        "            RandAdjustContrastd(keys=[\"vol\"] ,prob=0.5,gamma=gamma),\n",
        "\n",
        "            NormalizeIntensityd(keys=\"vol\", nonzero=True, channel_wise=True),\n",
        "            RandScaleIntensityd(keys=\"vol\", factors=0.1, prob=0.6),\n",
        "            RandShiftIntensityd(keys=\"vol\", offsets=0.1, prob=0.6),\n",
        "            ToTensord(keys=[\"vol\", \"seg\"]),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    val_transform = Compose(\n",
        "        [\n",
        "                LoadImaged(keys=[\"vol\", \"seg\"]),\n",
        "                EnsureChannelFirstd(keys=[\"vol\", \"seg\"]),\n",
        "                EnsureTyped(keys=[\"vol\", \"seg\"]),\n",
        "\n",
        "                Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
        "                Spacingd(keys=[\"vol\", \"seg\"], pixdim=pixdim, mode=(\"bilinear\", \"nearest\")),\n",
        "                RelabelTransform(keys=[\"seg\"], old_label=4, new_label=3),\n",
        "                SpatialCropd(keys=[\"vol\",\"seg\"], roi_center=roi_center ,roi_size=roi_size ),\n",
        "\n",
        "                RandGaussianNoised(keys=[\"vol\"], prob=0.6, mean=0.0, std=0.1),\n",
        "                NormalizeIntensityd(keys=\"vol\", nonzero=True, channel_wise=True),\n",
        "\n",
        "        ]\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    if cache:\n",
        "        train_ds = CacheDataset(\n",
        "            data=train_dataset,\n",
        "            transform=train_transform,\n",
        "            cache_rate=1.0,\n",
        "            num_workers=0,\n",
        "        )\n",
        "\n",
        "\n",
        "        val_ds = CacheDataset(\n",
        "            data=val_dataset,\n",
        "            transform=val_transform,\n",
        "            cache_rate=1.0,\n",
        "            num_workers=0,\n",
        "        )\n",
        "\n",
        "\n",
        "        return (\n",
        "    DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=0),\n",
        "    DataLoader(val_ds, batch_size=2, shuffle=True, num_workers=0)\n",
        ")\n",
        "\n",
        "\n",
        "    else:\n",
        "        train_ds = Dataset(\n",
        "                    data=train_dataset,\n",
        "                    transform=train_transform,\n",
        "                    cache_rate=1.0,\n",
        "                    num_workers=0,\n",
        "                )\n",
        "\n",
        "\n",
        "\n",
        "        val_ds = Dataset(\n",
        "                    data=val_dataset,\n",
        "                    transform=val_transform,\n",
        "                    cache_rate=1.0,\n",
        "                    num_workers=0,\n",
        "                )\n",
        "\n",
        "        return (\n",
        "    DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=0),\n",
        "    DataLoader(val_ds, batch_size=2, shuffle=True, num_workers=0)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSOIqa3OKL29"
      },
      "outputs": [],
      "source": [
        "from monai.utils import first\n",
        "import matplotlib.pyplot as plt\n",
        "def show_patient(tran_loader,val_loader,SLICE_NUMBER=1 ,train:bool=True,val:bool=False):\n",
        "\n",
        "    view_train_patient = first(tran_loader)\n",
        "    view_val_patient = first(val_loader)\n",
        "\n",
        "    if train:\n",
        "\n",
        "        # Create figure with proper size\n",
        "        plt.figure(figsize=(12, 6))\n",
        "\n",
        "        # First subplot (Original Image)\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.title(f'vol {SLICE_NUMBER}')\n",
        "\n",
        "        view_train_patient_image = np.array(view_train_patient['vol'][0, 0, :, :, SLICE_NUMBER], dtype=np.float16 )\n",
        "        plt.imshow(view_train_patient_image, cmap=\"gray\")\n",
        "\n",
        "        # Second subplot (Test Image)\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.title(f'seg {SLICE_NUMBER}')\n",
        "        view_train_patient_label = np.array(view_train_patient['seg'][0, 0, :, :, SLICE_NUMBER], dtype=np.float16)\n",
        "        plt.imshow(view_train_patient_label, cmap=\"gray\")\n",
        "\n",
        "        # Show the plot\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    if val:\n",
        "\n",
        "        # Create figure with proper size\n",
        "        plt.figure(figsize=(12, 6))\n",
        "\n",
        "        # First subplot (Original Image)\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.title(f'vol {SLICE_NUMBER}')\n",
        "\n",
        "        view_val_patient = np.array(view_val_patient['vol'][0, 0, :, :, SLICE_NUMBER], dtype=np.float16)\n",
        "        plt.imshow(view_val_patient, cmap=\"gray\")\n",
        "\n",
        "        # Second subplot (Test Image)\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.title(f'seg {SLICE_NUMBER}')\n",
        "        view_val_patient = np.array(view_val_patient['seg'][0, 0, :, :, SLICE_NUMBER], dtype=np.float16)\n",
        "        plt.imshow(view_val_patient, cmap=\"gray\")\n",
        "\n",
        "        # Show the plot\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxxg5mIHKL2-"
      },
      "outputs": [],
      "source": [
        "# Applying the transform to a single sample\n",
        "# sample = transforms(train_dataset[0])\n",
        "# print(f\"Volume shape: {sample['vol'].shape}\")\n",
        "# print(f\"Segmentation shape: {sample['seg'].shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOJ4HQ8mex_9"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "\n",
        "# # class SoftResurrectReLU(nn.Module):\n",
        "# #     def forward(self, x):\n",
        "# #         x = torch.clamp(x, -60, 60)  # to avoid overflow in exp\n",
        "# #         return torch.where(x >= 0, x, x + torch.exp(x))\n",
        "\n",
        "# # activation = SoftResurrectReLU()\n",
        "\n",
        "# class UNetEncoder(nn.Module):\n",
        "#     def __init__(self, in_channels, out_channels):\n",
        "#         super(UNetEncoder, self).__init__()\n",
        "#         self.activation = SoftResurrectReLU()\n",
        "#         self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "#         self.bn1 = nn.BatchNorm3d(out_channels)\n",
        "#         self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "#         self.bn2 = nn.BatchNorm3d(out_channels)\n",
        "#         self.pool = nn.MaxPool3d(2, 2)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.activation(self.bn1(self.conv1(x)))\n",
        "#         x = self.activation(self.bn2(self.conv2(x)))\n",
        "#         skip = x\n",
        "#         x = self.pool(x)\n",
        "#         return x, skip\n",
        "\n",
        "\n",
        "# class UNetDecoder(nn.Module):\n",
        "#     def __init__(self, in_channels, out_channels):\n",
        "#         super(UNetDecoder, self).__init__()\n",
        "#         self.upconv = nn.ConvTranspose3d(in_channels, out_channels, kernel_size=2, stride=2)\n",
        "#         self.conv1 = nn.Conv3d(out_channels * 2, out_channels, kernel_size=3, padding=1)\n",
        "#         self.bn1 = nn.BatchNorm3d(out_channels)\n",
        "#         self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "#         self.bn2 = nn.BatchNorm3d(out_channels)\n",
        "\n",
        "#     def forward(self, x, skip):\n",
        "#         x = self.upconv(x)\n",
        "#         x = torch.cat([x, skip], dim=1)\n",
        "#         x = self.activation(self.bn1(self.conv1(x)))\n",
        "#         x = self.activation(self.bn2(self.conv2(x)))\n",
        "#         return x\n",
        "\n",
        "\n",
        "# class UNetBottleneck(nn.Module):\n",
        "#     def __init__(self, in_channels, out_channels):\n",
        "#         super(UNetBottleneck, self).__init__()\n",
        "#         self.activation = SoftResurrectReLU()\n",
        "#         self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "#         self.bn1 = nn.BatchNorm3d(out_channels)\n",
        "#         self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "#         self.bn2 = nn.BatchNorm3d(out_channels)\n",
        "#         self.dropout = nn.Dropout3d(0.3)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.activation(self.bn1(self.conv1(x)))\n",
        "#         x = self.activation(self.bn2(self.conv2(x)))\n",
        "#         x = self.dropout(x)\n",
        "#         return x\n",
        "\n",
        "\n",
        "# class UnetModel(nn.Module):\n",
        "#     def __init__(self, num_classes):\n",
        "#         super(UnetModel, self).__init__()\n",
        "\n",
        "#         self.encoder1 = UNetEncoder(4, 32)\n",
        "#         self.encoder2 = UNetEncoder(32, 64)\n",
        "#         self.encoder3 = UNetEncoder(64, 128)\n",
        "#         self.encoder4 = UNetEncoder(128, 256)\n",
        "\n",
        "#         self.bottleneck = UNetBottleneck(256, 512)\n",
        "\n",
        "#         self.decoder1 = UNetDecoder(512, 256)\n",
        "#         self.decoder2 = UNetDecoder(256, 128)\n",
        "#         self.decoder3 = UNetDecoder(128, 64)\n",
        "#         self.decoder4 = UNetDecoder(64, 32)\n",
        "\n",
        "#         self.final_conv = nn.Conv3d(32, num_classes, kernel_size=1)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x, skip1 = self.encoder1(x)\n",
        "#         x, skip2 = self.encoder2(x)\n",
        "#         x, skip3 = self.encoder3(x)\n",
        "#         x, skip4 = self.encoder4(x)\n",
        "\n",
        "#         x = self.bottleneck(x)\n",
        "\n",
        "#         x = self.decoder1(x, skip4)\n",
        "#         x = self.decoder2(x, skip3)\n",
        "#         x = self.decoder3(x, skip2)\n",
        "#         x = self.decoder4(x, skip1)\n",
        "\n",
        "#         x = self.final_conv(x)\n",
        "#         return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yR53XNiKL2_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class UNetEncoder(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(UNetEncoder, self).__init__()\n",
        "        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm3d(out_channels)\n",
        "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm3d(out_channels)\n",
        "        self.pool = nn.MaxPool3d(2, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        skip = x\n",
        "        x = self.pool(x)\n",
        "        return x, skip\n",
        "\n",
        "\n",
        "class UNetDecoder(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(UNetDecoder, self).__init__()\n",
        "        self.upconv = nn.ConvTranspose3d(in_channels, out_channels, kernel_size=2, stride=2)\n",
        "        self.conv1 = nn.Conv3d(out_channels * 2, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm3d(out_channels)\n",
        "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm3d(out_channels)\n",
        "\n",
        "    def forward(self, x, skip):\n",
        "        x = self.upconv(x)\n",
        "        x = torch.cat([x, skip], dim=1)\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        return x\n",
        "\n",
        "\n",
        "class UNetBottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(UNetBottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm3d(out_channels)\n",
        "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm3d(out_channels)\n",
        "        self.dropout = nn.Dropout3d(0.3)  # %30 dropout\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class UnetModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(UnetModel, self).__init__()\n",
        "\n",
        "        self.encoder1 = UNetEncoder(4, 32)\n",
        "        self.encoder2 = UNetEncoder(32, 64)\n",
        "        self.encoder3 = UNetEncoder(64, 128)\n",
        "        self.encoder4 = UNetEncoder(128, 256)\n",
        "\n",
        "        self.bottleneck = UNetBottleneck(256, 512)\n",
        "\n",
        "        self.decoder1 = UNetDecoder(512, 256)\n",
        "        self.decoder2 = UNetDecoder(256, 128)\n",
        "        self.decoder3 = UNetDecoder(128, 64)\n",
        "        self.decoder4 = UNetDecoder(64, 32)\n",
        "\n",
        "        self.final_conv = nn.Conv3d(32, num_classes, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, skip1 = self.encoder1(x)\n",
        "        x, skip2 = self.encoder2(x)\n",
        "        x, skip3 = self.encoder3(x)\n",
        "        x, skip4 = self.encoder4(x)\n",
        "\n",
        "        x = self.bottleneck(x)\n",
        "\n",
        "        x = self.decoder1(x, skip4)\n",
        "        x = self.decoder2(x, skip3)\n",
        "        x = self.decoder3(x, skip2)\n",
        "        x = self.decoder4(x, skip1)\n",
        "\n",
        "        x = self.final_conv(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXT4WDn6KL3A"
      },
      "outputs": [],
      "source": [
        "model = UnetModel(4).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fW_1tk6rKL3B"
      },
      "outputs": [],
      "source": [
        "class CombinedLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.5, smooth=1e-6):\n",
        "        super(CombinedLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.smooth = smooth\n",
        "\n",
        "    def dice_loss(self, pred, target):\n",
        "        pred = torch.softmax(pred, dim=1)\n",
        "        intersection = (pred * target).sum(dim=(2, 3, 4))\n",
        "        union = pred.sum(dim=(2, 3, 4)) + target.sum(dim=(2, 3, 4))\n",
        "        dice = (2. * intersection + self.smooth) / (union + self.smooth)\n",
        "        return 1 - dice.mean()\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        dice = self.dice_loss(pred, target)\n",
        "        ce = nn.CrossEntropyLoss()(pred, target.argmax(dim=1))  # [B, 128, 128, 128]\n",
        "        return self.alpha * dice + (1 - self.alpha) * ce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIpRDudOKL3E"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Dice Score function\n",
        "def dice_score(pred, target, smooth=1e-6):\n",
        "    pred = torch.softmax(pred, dim=1)  # [B, 4, 128, 128, 128]\n",
        "    intersection = (pred * target).sum(dim=(2, 3, 4))\n",
        "    union = pred.sum(dim=(2, 3, 4)) + target.sum(dim=(2, 3, 4))\n",
        "    dice = (2. * intersection + smooth) / (union + smooth)\n",
        "    return dice.mean()\n",
        "\n",
        "def model_train(model, val_data, train_data,\n",
        "                model_train_val_metric_path=\"/content/drive/My Drive/Brain_tumor_train_val_metric\",\n",
        "                epochs=20, checkpoint_path=\"/content/drive/My Drive/Brain_tumor/unet_model_v1_refactored.pth\",\n",
        "                i=1):\n",
        "\n",
        "    save_loss_train = []\n",
        "    save_loss_val = []\n",
        "    save_metric_train = []\n",
        "    save_metric_val = []\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    model_concat_train_val_metric_path = \"/content/drive/My Drive/Brain_tumor_train_val_metric_concat\"\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
        "\n",
        "    if torch.cuda.device_count() > 1:\n",
        "        print(\"Using DataParallel for multi-GPU!\")\n",
        "        model = nn.DataParallel(model)\n",
        "    model.to(device)\n",
        "\n",
        "    criterion = CombinedLoss()  # Assuming CombinedLoss is defined somewhere\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=8e-5)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5)\n",
        "\n",
        "    # **Load previous checkpoint if available**\n",
        "\n",
        "    best_dice = 0.0  # remove it for already epoched dataset\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        print(f\"Loading previous checkpoint from {checkpoint_path}...\")\n",
        "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "\n",
        "        # Load the best Dice score if available\n",
        "        if 'best_dice' in checkpoint and checkpoint['best_dice'] is not None:\n",
        "            best_dice = checkpoint['best_dice']\n",
        "            print(f\"Loaded best Dice score from checkpoint: {best_dice:.4f}\")\n",
        "        else:\n",
        "            best_dice = 0.0\n",
        "            print(\"No best Dice score found in checkpoint. Using default value of 0.0.\")\n",
        "\n",
        "        # Load model state\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        print(\"Model state loaded successfully!\")\n",
        "\n",
        "        # Load optimizer state (add this)\n",
        "        if 'optimizer_state_dict' in checkpoint:\n",
        "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "            print(\"Optimizer state loaded successfully!\")\n",
        "        else:\n",
        "          print(\"No optimizer state found in checkpoint. Starting with a new optimizer.\")\n",
        "\n",
        "    else:\n",
        "        print(\"No checkpoint found. Starting training from scratch.\")\n",
        "\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10  # Early stopping\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        start_time = time.time()\n",
        "\n",
        "        # **Training Phase**\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_dice = 0\n",
        "        train_loader = tqdm(train_data, desc=f\"Epoch {epoch+1}/{epochs} [Train]\")\n",
        "\n",
        "        for batch_data in train_loader:\n",
        "\n",
        "\n",
        "            images, labels = batch_data['vol'], batch_data['seg']\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)  # [B, 4, 128, 128, 128]\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            train_dice += dice_score(outputs, labels).item()\n",
        "            train_loader.set_postfix({'train_loss': train_loss / (train_loader.n + 1)})\n",
        "\n",
        "        avg_train_loss = train_loss / len(train_data)\n",
        "        avg_train_dice = train_dice / len(train_data)\n",
        "\n",
        "        save_loss_train.append(avg_train_loss)\n",
        "        save_metric_train.append(avg_train_dice)\n",
        "\n",
        "        file_path_train_loss = os.path.join(model_concat_train_val_metric_path,f'loss_train_{i}.npy')\n",
        "        file_path_train_metric = os.path.join(model_concat_train_val_metric_path,f'metric_train_{i}.npy')\n",
        "\n",
        "        if os.path.exists(file_path_train_loss) and os.path.exists(file_path_train_metric):\n",
        "\n",
        "            # Load existing data\n",
        "            train_loss_data = np.load(file_path_train_loss)\n",
        "            train_metric_data = np.load(file_path_train_metric)\n",
        "\n",
        "            # Append along axis=0\n",
        "            train_loss_data = np.concatenate((train_loss_data, save_loss_train), axis=0)\n",
        "            train_metric_data = np.concatenate((train_metric_data, save_metric_train), axis=0)\n",
        "\n",
        "        else:\n",
        "        # If file doesn't exist, just use new_data as initial data\n",
        "            train_loss_data = save_loss_train\n",
        "            train_metric_data = save_metric_train\n",
        "\n",
        "\n",
        "        np.save(file_path_train_loss, train_loss_data)\n",
        "        np.save(file_path_train_metric, train_metric_data)\n",
        "\n",
        "        np.save(os.path.join(model_train_val_metric_path, 'loss_train.npy'), save_loss_train)\n",
        "        np.save(os.path.join(model_train_val_metric_path, 'metric_train.npy'), save_metric_train)\n",
        "\n",
        "\n",
        "        # **Validation Phase**\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        val_dice = 0\n",
        "        val_loader = tqdm(val_data, desc=f\"Epoch {epoch+1}/{epochs} [Val]\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            for batch_data in val_loader:\n",
        "\n",
        "\n",
        "                images, labels = batch_data['vol'], batch_data['seg']\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "                val_dice += dice_score(outputs, labels).item()\n",
        "\n",
        "                val_loader.set_postfix({'val_loss': val_loss / (val_loader.n + 1),\n",
        "                                        'val_dice': val_dice / (val_loader.n + 1)})\n",
        "\n",
        "        avg_val_loss = val_loss / len(val_data)\n",
        "        avg_val_dice = val_dice / len(val_data)\n",
        "\n",
        "        save_loss_val.append(avg_val_loss)\n",
        "        save_metric_val.append(avg_val_dice)\n",
        "\n",
        "\n",
        "        file_path_val_loss = os.path.join(model_concat_train_val_metric_path,f'loss_val_{i}.npy')\n",
        "        file_path_val_metric = os.path.join(model_concat_train_val_metric_path,f'metric_val_{i}.npy')\n",
        "\n",
        "        if os.path.exists(file_path_val_loss) and os.path.exists(file_path_val_metric):\n",
        "\n",
        "            # Load existing data\n",
        "            val_loss_data = np.load(file_path_val_loss)\n",
        "            val_metric_data = np.load(file_path_val_metric)\n",
        "\n",
        "            # Append along axis=0\n",
        "            val_loss_data = np.concatenate((val_loss_data, save_loss_val), axis=0)\n",
        "            val_metric_data = np.concatenate((val_metric_data, save_metric_val), axis=0)\n",
        "\n",
        "        else:\n",
        "        # If file doesn't exist, just use new_data as initial data\n",
        "            val_loss_data = save_loss_val\n",
        "            val_metric_data = save_metric_val\n",
        "\n",
        "\n",
        "        np.save(file_path_val_loss, val_loss_data)\n",
        "        np.save(file_path_val_metric, val_metric_data)\n",
        "\n",
        "        np.save(os.path.join(model_train_val_metric_path, 'loss_val.npy'), save_loss_val)\n",
        "        np.save(os.path.join(model_train_val_metric_path, 'metric_val.npy'), save_metric_val)\n",
        "\n",
        "\n",
        "        scheduler.step(avg_val_loss)\n",
        "\n",
        "        epoch_duration = time.time() - start_time\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{epochs}')\n",
        "        print(f'Training Loss: {avg_train_loss:.4f}')\n",
        "        print(f'Training Loss: {avg_train_dice:.4f}')\n",
        "        print(f'Validation Loss: {avg_val_loss:.4f}')\n",
        "        print(f'Validation Dice: {avg_val_dice:.4f}')\n",
        "        print(f'Time Taken: {epoch_duration:.2f} seconds')\n",
        "        print('-' * 50)\n",
        "\n",
        "        # **Save the best model based on Dice Score**\n",
        "        if avg_val_dice > best_dice:\n",
        "            best_dice = avg_val_dice\n",
        "            best_val_loss = avg_val_loss\n",
        "\n",
        "                    # Save the best model only\n",
        "                    # Save the model along with the best dice score\n",
        "            torch.save({\n",
        "                        'model_state_dict': model.state_dict(),\n",
        "                        'optimizer_state_dict': optimizer.state_dict(),\n",
        "                        'best_dice': best_dice\n",
        "                        }, \"/content/drive/My Drive/Brain_tumor/unet_model_v02_refactored.pth\")\n",
        "\n",
        "            print(f\"Best model saved with Dice: {best_dice:.4f}, Val Loss: {best_val_loss:.4f}\")\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                torch.save({\n",
        "                        'model_state_dict': model.state_dict(),\n",
        "                        'optimizer_state_dict': optimizer.state_dict(),\n",
        "                        'best_dice': best_dice\n",
        "                          }, \"/content/drive/My Drive/Brain_tumor/unet_model_v100_refactored.pth\")\n",
        "\n",
        "                break\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9Mu75kHOcDz",
        "outputId": "bd51ce87-aa00-4b38-9365-922c2a7b1f56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading dataset: 100%|██████████| 80/80 [08:40<00:00,  6.51s/it]\n",
            "Loading dataset: 100%|██████████| 20/20 [02:10<00:00,  6.51s/it]\n"
          ]
        }
      ],
      "source": [
        "train_path = r\"/content/drive/My Drive/MICCAI_BraTS2020_TrainingData\"\n",
        "train_loader , val_loader = prepare(in_dir=train_path,start_file=0,end_file=100,train_size=0.8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjdEMYRcKL3G",
        "outputId": "4b07d04c-a52f-4e46-ec76-b30a3e62b3d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "cpu\n"
          ]
        }
      ],
      "source": [
        "print(next(model.parameters()).device)\n",
        "print(next(model.parameters()).device)  # Should print cuda:0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "C-SBZrHNKL3G",
        "outputId": "0e6500da-8f7c-4fa6-b094-5314189318e8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1302941838bd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/drive/My Drive/Brain_tumor/unet_model_v01_refactored.pth\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model_train' is not defined"
          ]
        }
      ],
      "source": [
        "model_train(model, val_data=val_loader, train_data= train_loader, epochs=10,checkpoint_path=\"/content/drive/My Drive/Brain_tumor/unet_model_v01_refactored.pth\",i=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8LiT22bUyve"
      },
      "outputs": [],
      "source": [
        "# x = torch.randn(2, 3, 32, 32, 32).cuda()\n",
        "# act = SoftResurrectReLU().cuda()\n",
        "# out = act(x)\n",
        "# print(out.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLcJaKo4KL3G"
      },
      "outputs": [],
      "source": [
        "model_dir = \"/content/drive/My Drive/Brain_tumor_train_val_metric\"\n",
        "train_loss = np.load(os.path.join(model_dir, 'loss_train.npy'))\n",
        "train_metric = np.load(os.path.join(model_dir, 'metric_train.npy'))\n",
        "val_loss = np.load(os.path.join(model_dir, 'loss_val.npy'))\n",
        "val_metric = np.load(os.path.join(model_dir, 'metric_val.npy'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vE2P95GuKL3G"
      },
      "outputs": [],
      "source": [
        "plt.figure(\"Results 25 june\", (10, 10))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.title(\"Train dice loss\")\n",
        "x = [i + 1 for i in range(len(train_loss))]\n",
        "y = train_loss\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(x, y)\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.title(\"Train metric DICE\")\n",
        "x = [i + 1 for i in range(len(train_metric))]\n",
        "y = train_metric\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(x, y)\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.title(\"Test dice loss\")\n",
        "x = [i + 1 for i in range(len(val_loss))]\n",
        "y = val_loss\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(x, y)\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.title(\"Test metric DICE\")\n",
        "x = [i + 1 for i in range(len(val_metric))]\n",
        "y = val_metric\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(x, y)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8nuDi8hOmgm"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(),\"/content/drive/My Drive/Brain_tumor/tumor_unet_model_v02_refactored.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yf5J0Ez_StT2"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}