{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52ae36eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8328cf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multi_vector_retriever(vectorstore,text_summaries,texts,tables_summaries,tables,image_summaries,images):\n",
    "    \n",
    "    \"\"\"\n",
    "    create retriever that indexes summarieses , but returns raw image or texts\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialization\n",
    "    \n",
    "    store = InMemoryStore()\n",
    "    id_key='doc_id'\n",
    "    \n",
    "    \n",
    "    #create the mmutli-vector retriever\n",
    "    \n",
    "    retriever = MultiVectorRetriever(\n",
    "        vectorstore=vectorstore,\n",
    "        docstore=store,\n",
    "        id_key=id_key\n",
    "    )\n",
    "    \n",
    "    \n",
    "    def add_documents(retriever,doc_summaries,doc_contents):\n",
    "        \n",
    "        doc_ids = [str(uuid.uuid4()) for _ in doc_contents ]\n",
    "        \n",
    "        summary_docs = [\n",
    "            Document(page_contents = s ,metadata={id_key:doc_ids[i]})\n",
    "            for i,s in enumerate(doc_summaries)\n",
    "        ]\n",
    "        \n",
    "        retriever.vectorstore.add_documents(summary_docs)\n",
    "        retriever.docstore.mset(list(zip(doc_ids,doc_contents)))\n",
    "        \n",
    "        \n",
    "        #add text tables images/\n",
    "        #check that text summaries is not emty before adding \n",
    "        \n",
    "        if text_summaries:\n",
    "            add_documents(retriever,text_summaries,texts)\n",
    "            \n",
    "        # check for table too\n",
    "        \n",
    "        if tables_summaries:\n",
    "            add_documents(retriever,tables_summaries,tables)\n",
    "            \n",
    "        if image_summaries:\n",
    "            add_documents(retriever,image_summaries,images)\n",
    "            \n",
    "            \n",
    "        return retriever\n",
    "    \n",
    "vectorstore = Chroma(\n",
    "    collection_name = \"mm_rag\",embedding_function=OpenAIEmbeddings()\n",
    ")\n",
    "\n",
    "## create retriever\n",
    "\n",
    "retriever_multi_vector_img = create_multi_vector_retriever(\n",
    "    vectorstore,\n",
    "    text_summaries,\n",
    "    Text,\n",
    "    tables_summaries,\n",
    "    Table,\n",
    "    image_summaries,\n",
    "    img_base64_list,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e674b22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_multi_vector_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec590e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io,re\n",
    "from IPython.display import HTML,display\n",
    "from PIL import Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e15f339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_img_base64(img_base64):\n",
    "    \n",
    "    image_html = f'<img src=\"data:image/jpeg;base64\",{img_base64} />'\n",
    "    \n",
    "    display(HTML(image_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac6e054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_img_base64(img_base64):\n",
    "    \n",
    "    image_html = f'<img src=\"data:image/jpeg;base64\",{img_base64} />'\n",
    "    \n",
    "    display(HTML(image_html))\n",
    "    \n",
    "plt_img_base64(img_base64_list[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc50747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def looks_like_base64(sb):\n",
    "    \"\"\"\n",
    "    check if the string looks like base64\n",
    "    \"\"\"\n",
    "    \n",
    "    return re.match(\"^[A-Za-z0-9+/]+[=]{0,2}$\",sb) is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be6a5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_image_data(b64data):\n",
    "    \"\"\"\n",
    "    Check if the base64 data is an image by looking at the start of the data\n",
    "    \"\"\"\n",
    "    image_signatures = {\n",
    "        b\"\\xFF\\xD8\\xFF\": \"jpg\",\n",
    "        b\"\\x89\\x50\\x4E\\x47\\x0D\\x0A\\x1A\\x0A\": \"png\",\n",
    "        b\"\\x47\\x49\\x46\\x38\": \"gif\",\n",
    "        b\"\\x52\\x49\\x46\\x46\": \"webp\",\n",
    "    }\n",
    "    try:\n",
    "        header = base64.b64decode(b64data)[:8]  # Decode and get the first 8 bytes\n",
    "        for sig, format in image_signatures.items():\n",
    "            if header.startswith(sig):\n",
    "                return True\n",
    "        return False\n",
    "    except Exception:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac0e2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_base64_image(base64_string,size=(128,128)):\n",
    "    \"\"\"\n",
    "    Resize an image encoded as base64 string\n",
    "    \"\"\"\n",
    "    \n",
    "    # decode the base64 string\n",
    "    \n",
    "    img_data = base64.b64decode(base64_string)\n",
    "    img= Image.open(io.BytesIO(img_data))\n",
    "    \n",
    "    #resize images\n",
    "    resized_img = img.resize(size,Image.LANCZOS)\n",
    "    \n",
    "    # save the resized image to a bytes buffer\n",
    "    buffered = io.BytesIO()\n",
    "    resized_img.save(buffered,format=img.format)\n",
    "    \n",
    "    \n",
    "    # encode the resized image to base64\n",
    "    return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668bced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_image_text_types(docs):\n",
    "    \"\"\"\n",
    "    Split base64-encoded images and texts\n",
    "    \"\"\"\n",
    "    \n",
    "    b64_images = []\n",
    "    texts = []\n",
    "    \n",
    "    for doc in docs:\n",
    "        \n",
    "        #check if the document(doc) is of the type document and extract page_content if sorted\n",
    "        if isinstance(doc,Document):\n",
    "            doc = doc.page_content\n",
    "            \n",
    "        if looks_like_base64(doc) and is_image_data(doc):\n",
    "            \n",
    "            doc = resize_base64_image(doc,size=(1300,600))\n",
    "            b64_images.append(doc)\n",
    "            \n",
    "        else:\n",
    "            texts.append(doc)\n",
    "            \n",
    "    print(b64_images)\n",
    "    print(texts)\n",
    "        \n",
    "    return {\"images\":b64_images ,\n",
    "                \"texts\":texts\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4908b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_prompt_func(data_dict):\n",
    "    \"\"\"\n",
    "    Join the context into a single string\n",
    "    \"\"\"\n",
    "    # print(data_dict)\n",
    "    formatted_texts = \"\\n\".join(data_dict[\"context\"][\"texts\"])\n",
    "    messages = []\n",
    "\n",
    "    # Adding image(s) to the messages if present\n",
    "    if data_dict[\"context\"][\"images\"]:\n",
    "        for image in data_dict[\"context\"][\"images\"]:\n",
    "            image_message = {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image}\"},\n",
    "            }\n",
    "            messages.append(image_message)\n",
    "\n",
    "    # Adding the text for analysis\n",
    "    text_message = {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": (\n",
    "            \"You are a helpful assistant.\\n\"\n",
    "            \"You will be given a mixed info(s).\\n\"\n",
    "            \"Use this information to provide relevant information to the user question.\\n\"\n",
    "            f\"User-provided question: {data_dict['question']}\\n\\n\"\n",
    "            \"Text and/or tables:\\n\"\n",
    "            f\"{formatted_texts}\"\n",
    "        ),\n",
    "    }\n",
    "    messages.append(text_message)\n",
    "\n",
    "    return [HumanMessage(content=messages)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9067ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda,RunnablePassthrough\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import StrOutputParser\n",
    "\n",
    "\n",
    "def multi_model_rag_chain(retriever):\n",
    "    \"\"\"\n",
    "    Multi model RAG chain\n",
    "    \"\"\"\n",
    "    \n",
    "    model = ChatOpenAI(temperature=0,model=\"gpt-5-vision-preview\",max_tokens=1024)\n",
    "    \n",
    "    \n",
    "    # RAG pipeline\n",
    "    \n",
    "    chain = (\n",
    "        {\n",
    "            \"context\": retriever | RunnableLambda(split_image_text_types),\n",
    "            \"question\": RunnablePassthrough(),\n",
    "            \n",
    "        }\n",
    "        | RunnableLambda(img_prompt_func)\n",
    "        | model\n",
    "        | StrOutputParser()\n",
    "        \n",
    "    )\n",
    "    \n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1711a420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create RAG chain\n",
    "\n",
    "chain_multi_model_rag = multi_model_rag_chain(retriever_multi_vector_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddda412",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_multi_model_rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b325ee2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"whats the paper about ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90dde15",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_multi_model_rag.invoke(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
